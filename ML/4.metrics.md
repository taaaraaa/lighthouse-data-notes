# How good did your model do?

### Type l Error: False Negative
### Type ll Error: False Positive

## Classification metrics

### 1. Accuracy
The proportion of correct predictions (true positives + true negatives) out of all predictions

### 2. Precision
The proportion of true positives out of all positive predictions

### 3. Recall
the proportion of true positives out of all actual positive cases

### 4. F1 score
The harmonic mean of precision and recall

### 5.AUC (Area Under the ROC Curve)
A measure of the model's ability to discriminate between positive and negative cases

----
## Regression metrics

### 1. MSE (Mean Squared Error):

The average squared difference between the predicted and actual values

### 2. MAE (Mean Absolute Error):
The average absolute difference between the predicted and actual values

### 3. R^2
The proportion of variance in the dependent variable that is explained by the model

------------
